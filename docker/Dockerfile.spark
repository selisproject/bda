FROM openjdk:latest

ARG HADOOP_FILE=hadoop-2.9.1
ARG HADOOP_PREFIX=/usr/local/hadoop
ARG HADOOP_TAR_FILE=hadoop-2.9.1.tar.gz
ARG HADOOP_DOWNLOAD_URL=http://apache.mirrors.spacedump.net/hadoop/common/stable/hadoop-2.9.1.tar.gz

ARG SPARK_PREFIX=/usr/local/spark
ARG SPARK_FILE=spark-2.3.1-bin-without-hadoop
ARG SPARK_TAR_FILE=spark-2.3.1-bin-without-hadoop.tgz
ARG SPARK_DOWNLOAD_URL=https://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-without-hadoop.tgz

# Install general packages.
RUN apt-get update && apt-get install -y \
    apt-transport-https \
    ca-certificates \
    python3 \
    python3-pip \ 
    vim

RUN apt-get clean

RUN pip3 install \
    psycopg2 \
    py-dateutil \
    requests

# Download hadoop.
RUN wget ${HADOOP_DOWNLOAD_URL} --directory-prefix /tmp
# COPY ${HADOOP_TAR_FILE} /tmp

# Untar and link to `/usr/local/hadoop`.
RUN tar -xzf /tmp/${HADOOP_TAR_FILE} -C /usr/local/
RUN rm /tmp/${HADOOP_TAR_FILE}
RUN ln -s /usr/local/${HADOOP_FILE} ${HADOOP_PREFIX}

# Set hadoop/yarn environment variables.
ENV HADOOP_PREFIX      "${HADOOP_PREFIX}"
ENV HADOOP_HOME        "${HADOOP_PREFIX}"
ENV HADOOP_COMMON_HOME "${HADOOP_PREFIX}"
ENV HADOOP_CONF_DIR    "${HADOOP_PREFIX}/etc/hadoop"
ENV HADOOP_HDFS_HOME   "${HADOOP_PREFIX}"
ENV HADOOP_MAPRED_HOME "${HADOOP_PREFIX}"
ENV HADOOP_YARN_HOME   "${HADOOP_PREFIX}"
ENV YARN_CONF_DIR      "${HADOOP_PREFIX}/etc/hadoop"

# Add configuration files.
ADD ./bootstrap/spark/hdfs-site.xml "${HADOOP_PREFIX}/etc/hadoop/"
ADD ./bootstrap/spark/core-site.xml "${HADOOP_PREFIX}/etc/hadoop/"
ADD ./bootstrap/spark/yarn-site.xml "${HADOOP_PREFIX}/etc/hadoop/"

# Download spark.
RUN wget ${SPARK_DOWNLOAD_URL} --directory-prefix /tmp
# COPY ${SPARK_TAR_FILE} /tmp

# Untar and link to `/usr/local/spark`.
RUN tar -xzf /tmp/${SPARK_TAR_FILE} -C /usr/local/
RUN rm /tmp/${SPARK_TAR_FILE}
RUN ln -s /usr/local/${SPARK_FILE} ${SPARK_PREFIX}

# Set spark environment variables.
ENV SPARK_HOME "${SPARK_PREFIX}"

ADD ./bootstrap/spark/entrypoint.sh /
